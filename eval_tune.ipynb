{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook for looking at the tuning results using the get_best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import base_directories\n",
    "from tune import get_best_models, get_model_losses\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "dir_settings = base_directories.get_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{70: {'save_model': True, 'n_models': 100, 'ssp': '370', 'ensemble_data': False, 'gcmsub': 'ALL', 'obsdata': 'ERA5', 'smooth': False, 'model_type': 'static_window', 'len_window': 10, 'n_train_val_test': (20, 10, 0), 'no_test': True, 'baseline_yr_bounds': (1850, 1899), 'training_yr_bounds': (1951, 2080), 'anomaly_yr_bounds': (1951, 1980), 'remove_sh': False, 'anomalies': True, 'remove_map_mean': False, 'input_fields': ('timemean=10_spatialmean=global', 'timemean=1'), 'network_type': 'shash2', 'hiddens1': (2, 2, 2), 'hiddens2': '[100, 100]', 'hiddens3': '[1, 1]', 'dropout_rate': 0.0, 'ridge_param1': 0, 'ridge_param2': 0.01, 'ridge_param3': 0, 'learning_rate': 0.0001, 'baseline_learning_rate': 0.01, 'batch_size': 64, 'rng_seed': 0, 'seed': 0, 'act_fun1': 'gelu', 'act_fun2': 'relu', 'act_fun3': 'elu', 'n_epochs': 25000, 'patience': 50, 'exp_name': 'tune10', 'train_models': '[20, 4, 3, 29, 6, 14, 28, 24, 7, 13, 18, 16, 26, 17, 15, 1, 9, 11, 25, 0]', 'val_models': '[5, 2, 23, 10, 12, 22, 27, 21, 19, 8]', 'test_models': '[5, 2, 23, 10, 12, 22, 27, 21, 19, 8]', 'results': {'val_loss': -0.25222048163414, 'obs_loss': -0.5467915534973145, 'test_loss': -0.25222048163414, 'test12_loss': -0.38113927841186523, 'obs_nopinatubo_loss': -0.6383657455444336, 'val_mae': 0.8208501935005188, 'obs_mae': 0.4155948758125305, 'test_mae': 0.8208501935005188, 'test12_mae': 0.7065572738647461, 'obs_nopinatubo_mae': 0.49271318316459656, 'bl_val_loss': -0.20156915485858917, 'bl_obs_loss': -0.541217029094696, 'bl_test_loss': -0.20156915485858917, 'bl_test12_loss': -0.3279598355293274, 'bl_obs_nopinatubo_loss': -0.48283904790878296, 'bl_val_mae': 0.14965881407260895, 'bl_obs_mae': 0.0862424299120903, 'bl_test_mae': 0.14965881407260895, 'bl_test12_mae': 0.13176745176315308, 'bl_obs_nopinatubo_mae': 0.10473837703466415, 'obs20C_loss': -0.6465792655944824, 'obs20C_mae': 0.2998802661895752, 'bl_obs20C_loss': -0.5853836536407471, 'bl_obs20C_mae': 0.06504638493061066}}}\n"
     ]
    }
   ],
   "source": [
    "tuner_dict = get_best_models(\"basetune1\", num_models=1, track_loss = 'test')\n",
    "which = 0\n",
    "print(tuner_dict[list(tuner_dict.keys())[which]][\"hiddens1\"])\n",
    "print(tuner_dict[list(tuner_dict.keys())[which]][\"act_fun1\"])\n",
    "print(tuner_dict[list(tuner_dict.keys())[which]][\"baseline_learning_rate\"])\n",
    "# print(tuner_dict[list(tuner_dict.keys())[which]][\"hiddens2\"])\n",
    "# print(tuner_dict[list(tuner_dict.keys())[which]][\"hiddens3\"])\n",
    "# print(tuner_dict[list(tuner_dict.keys())[which]][\"learning_rate\"])\n",
    "# print(tuner_dict[list(tuner_dict.keys())[which]][\"act_fun2\"])\n",
    "# print(tuner_dict[list(tuner_dict.keys())[which]][\"act_fun3\"])\n",
    "# print(tuner_dict[list(tuner_dict.keys())[which]][\"ridge_param2\"])\n",
    "print(tuner_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
